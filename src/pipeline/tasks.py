# src/pipeline/tasks.py
from celery import current_task
from celery.utils.log import get_task_logger
from celery import group, chord, chain
import sys
import os
import importlib.util

# Agregar path del proyecto
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Importar la aplicaci√≥n Celery
from src.celery_app import app

# Configurar logger
logger = get_task_logger(__name__)

# =============================================
# FUNCIONES AUXILIARES PARA IMPORTAR M√ìDULOS CON N√öMEROS
# =============================================

def import_production_module(filename, function_name):
    """Importa din√°micamente m√≥dulos de producci√≥n que empiezan con n√∫meros"""
    module_path = os.path.join(project_root, 'src', 'production', filename)
    spec = importlib.util.spec_from_file_location(filename.replace('.py', ''), module_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    return getattr(module, function_name)

# =============================================
# TAREAS INDIVIDUALES (Conversi√≥n de tus scripts)
# =============================================

@app.task(bind=True, max_retries=3, default_retry_delay=60)
def ingest_data_task(self):
    """Convierte tu script 01_ingest_daily_data.py en tarea Celery"""
    try:
        logger.info("üîÑ Iniciando ingesta de datos...")
        
        # Importar din√°micamente el m√≥dulo con n√∫mero
        run_daily_ingestion = import_production_module('01_ingest_daily_data.py', 'run_daily_ingestion')
        
        # Ejecutar la funci√≥n principal
        run_daily_ingestion()
        
        logger.info("‚úÖ Ingesta de datos completada")
        return {"status": "success", "task": "ingest_data", "result": "completed"}
        
    except Exception as exc:
        logger.error(f"‚ùå Error en ingesta de datos: {exc}")
        if self.request.retries < 3:
            logger.info(f"üîÑ Reintentando ingesta... ({self.request.retries + 1}/3)")
            raise self.retry(exc=exc, countdown=60)
        else:
            logger.error("üíÄ Ingesta fall√≥ despu√©s de 3 intentos")
            raise

@app.task(bind=True, max_retries=3, default_retry_delay=60)
def prepare_features_task(self, previous_result=None):
    """Convierte tu script 02_prepare_features.py en tarea Celery"""
    try:
        logger.info("üîÑ Iniciando preparaci√≥n de caracter√≠sticas...")
        
        # Importar din√°micamente el m√≥dulo con n√∫mero
        run_feature_preparation = import_production_module('02_prepare_features.py', 'run_feature_preparation')
        
        # Tu funci√≥n no retorna nada, pero eso est√° bien
        run_feature_preparation()
        
        logger.info("‚úÖ Preparaci√≥n de caracter√≠sticas completada")
        return {"status": "success", "task": "prepare_features", "result": "completed"}
        
    except Exception as exc:
        logger.error(f"‚ùå Error en preparaci√≥n de caracter√≠sticas: {exc}")
        if self.request.retries < 3:
            logger.info(f"üîÑ Reintentando preparaci√≥n... ({self.request.retries + 1}/3)")
            raise self.retry(exc=exc, countdown=60)
        else:
            logger.error("üíÄ Preparaci√≥n fall√≥ despu√©s de 3 intentos")
            raise

@app.task(bind=True, max_retries=3, default_retry_delay=60)  
def generate_signals_task(self, previous_result=None):
    """Convierte tu script 03_generate_signals.py en tarea Celery"""
    try:
        logger.info("üîÑ Iniciando generaci√≥n de se√±ales...")
        
        # Importar din√°micamente el m√≥dulo con n√∫mero
        run_inference = import_production_module('03_generate_signals.py', 'run_inference')
        
        # Tu funci√≥n no retorna nada, pero genera signals.json
        run_inference()
        
        logger.info("‚úÖ Generaci√≥n de se√±ales completada")
        return {"status": "success", "task": "generate_signals", "result": "completed"}
        
    except Exception as exc:
        logger.error(f"‚ùå Error en generaci√≥n de se√±ales: {exc}")
        if self.request.retries < 3:
            logger.info(f"üîÑ Reintentando generaci√≥n... ({self.request.retries + 1}/3)")
            raise self.retry(exc=exc, countdown=60)
        else:
            logger.error("üíÄ Generaci√≥n de se√±ales fall√≥ despu√©s de 3 intentos")
            raise

@app.task(bind=True, max_retries=2, default_retry_delay=30)
def execute_trades_task(self, previous_result=None):
    """Convierte tu script 04_execution_engine.py en tarea Celery"""
    try:
        logger.info("üîÑ Iniciando ejecuci√≥n de trades...")
        
        # Importar din√°micamente el m√≥dulo con n√∫mero
        run_execution_engine = import_production_module('04_execution_engine.py', 'run_execution_engine')
        
        # Tu funci√≥n no retorna nada, pero ejecuta las √≥rdenes
        run_execution_engine()
        
        logger.info("‚úÖ Ejecuci√≥n de trades completada")
        return {"status": "success", "task": "execute_trades", "result": "completed"}
        
    except Exception as exc:
        logger.error(f"‚ùå Error en ejecuci√≥n de trades: {exc}")
        if self.request.retries < 2:
            logger.info(f"üîÑ Reintentando ejecuci√≥n... ({self.request.retries + 1}/2)")
            raise self.retry(exc=exc, countdown=30)
        else:
            logger.error("üíÄ Ejecuci√≥n de trades fall√≥ despu√©s de 2 intentos")
            raise

# =============================================
# PIPELINES COMPLEJOS (Workflows)
# =============================================

@app.task
def health_check_task():
    """Tarea de verificaci√≥n de salud del sistema"""
    try:
        logger.info("üè• Ejecutando health check del sistema...")
        
        from src.pipeline.monitoring import CryptonitaPipelineMonitor
        monitor = CryptonitaPipelineMonitor()
        
        health_status = monitor.health_check()
        signals_status = monitor.check_signals_file()
        
        logger.info(f"üìä Estado del sistema: {health_status['status']}")
        logger.info(f"üìã Estado de se√±ales: {signals_status['status']}")
        
        return {
            "status": "success",
            "task": "health_check", 
            "system_health": health_status,
            "signals_health": signals_status
        }
        
    except Exception as exc:
        logger.error(f"‚ùå Error en health check: {exc}")
        return {"status": "error", "task": "health_check", "error": str(exc)}

@app.task
def pipeline_complete_callback(results):
    """Se ejecuta cuando termina todo el pipeline"""
    logger.info(f"üéâ Pipeline completado: {len(results)} tareas")
    
    # Analizar resultados
    successful = sum(1 for r in results if r and r.get('status') == 'success')
    logger.info(f"üìä Exitosas: {successful}/{len(results)}")
    
    return {
        "pipeline_status": "completed", 
        "success_count": successful,
        "total_tasks": len(results),
        "timestamp": str(current_task.request.id)
    }

@app.task
def run_complete_pipeline():
    """Ejecuta el pipeline completo secuencial"""
    logger.info("üöÄ Iniciando pipeline completo de trading")
    
    # Crear cadena secuencial: ingest -> features -> signals -> execute
    workflow = chain(
        ingest_data_task.s(),
        prepare_features_task.s(),
        generate_signals_task.s(),
        execute_trades_task.s()
    )
    
    # Ejecutar workflow y agregar callback
    job = chord([workflow])(pipeline_complete_callback.s())
    
    logger.info(f"Pipeline iniciado con job_id: {job.id}")
    return f"Pipeline iniciado con job_id: {job.id}"