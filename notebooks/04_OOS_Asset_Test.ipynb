{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ec3c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Construyendo DataFrame para el Nuevo Universo ---\n",
      "\n",
      " -> Paso 1: Descargando datos de precios...\n",
      "‚úÖ Precios descargados (5020 filas).\n",
      "\n",
      " -> Paso 2: Descargando funding rates de Binance...\n",
      "  -> Descargando funding rates para AVAX-USD (AVAXUSDT)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:41: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_raw = yf.download(new_ticker_list, start=start_date, end=end_date, progress=False)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:46: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
      "  df_processed = df_raw.stack(level=1).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para ATOM-USD (ATOMUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para NEAR-USD (NEARUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para FTM-USD (FTMUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para UNI-USD (UNIUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para AAVE-USD (AAVEUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para ALGO-USD (ALGOUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para TRX-USD (TRXUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para XLM-USD (XLMUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "  -> Descargando funding rates para XTZ-USD (XTZUSDT)...\n",
      "    ‚úÖ 1507 registros de funding rate obtenidos\n",
      "‚úÖ Funding rates procesados (15070 registros totales)\n",
      "\n",
      " -> Paso 3: Calculando indicadores t√©cnicos...\n",
      "‚úÖ Indicadores t√©cnicos calculados\n",
      "\n",
      " -> Paso 4: Cargando datos macro desde la base de datos...\n",
      "  ‚úÖ macro_spy: 346 registros cargados\n",
      "  ‚úÖ macro_vix: 346 registros cargados\n",
      "  ‚úÖ macro_tnx: 346 registros cargados\n",
      "  ‚úÖ macro_dxy: 346 registros cargados\n",
      "  ‚úÖ macro_gc: 346 registros cargados\n",
      "  ‚úÖ macro_cl: 346 registros cargados\n",
      "‚úÖ Datos macro unidos al DataFrame principal\n",
      "\n",
      " -> Paso 5: Uniendo funding rates...\n",
      "‚úÖ Funding rates unidos\n",
      "\n",
      " -> Paso 6: Creando features adicionales...\n",
      "‚úÖ Features adicionales creadas\n",
      "\n",
      " -> Paso 7: Aplicando correcci√≥n de look-ahead bias...\n",
      "‚úÖ Look-ahead bias corregido y columnas filtradas\n",
      "\n",
      " -> Paso 9: Guardando DataFrame final...\n",
      "\n",
      "üéâ ¬°√âXITO COMPLETO!\n",
      "üìÅ DataFrame guardado en: dataframes/master_df_new_universe_complete.parquet\n",
      "üìä Shape final: (2710, 17)\n",
      "üìã Columnas finales: ['timestamp', 'ticker', 'close', 'macd_signal', 'macd_hist', 'funding_rate', 'spy_close', 'vix_close', 'tnx_close', 'dxy_close', 'gc_close', 'cl_close', 'log_return', 'volatility_7d', 'price_to_ema_ratio', 'macd_norm', 'log_return_gc_close']\n",
      "\n",
      "--- RESUMEN POR TICKER ---\n",
      "          Records                Start_Date                  End_Date\n",
      "ticker                                                               \n",
      "AAVE-USD      271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "ALGO-USD      271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "ATOM-USD      271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "AVAX-USD      271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "FTM-USD       271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "NEAR-USD      271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "TRX-USD       271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "UNI-USD       271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "XLM-USD       271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "XTZ-USD       271 2020-12-04 00:00:00+00:00 2022-04-14 00:00:00+00:00\n",
      "\n",
      "--- MUESTRA DE DATOS ---\n",
      "                  timestamp    ticker      close  macd_signal  macd_hist  \\\n",
      "0 2020-12-04 00:00:00+00:00  AAVE-USD  81.641823     0.555457   1.490806   \n",
      "1 2020-12-08 00:00:00+00:00  AAVE-USD  79.946190     2.087870   1.627642   \n",
      "2 2020-12-09 00:00:00+00:00  AAVE-USD  82.113724     2.299304   0.845736   \n",
      "3 2020-12-10 00:00:00+00:00  AAVE-USD  76.645760     2.406474   0.428682   \n",
      "4 2020-12-11 00:00:00+00:00  AAVE-USD  74.729828     2.349953  -0.226084   \n",
      "\n",
      "   funding_rate   spy_close  vix_close  tnx_close  dxy_close     gc_close  \\\n",
      "0      0.000279  345.752563  20.790001      0.969  90.699997  1835.900024   \n",
      "1      0.000173  346.051727  20.680000      0.913  90.970001  1870.800049   \n",
      "2      0.000205  342.948059  22.270000      0.941  91.089996  1834.599976   \n",
      "3      0.000124  342.835846  22.520000      0.908  90.790001  1833.599976   \n",
      "4      0.000177  342.433868  23.309999      0.893  90.980003  1839.800049   \n",
      "\n",
      "    cl_close  log_return  volatility_7d  price_to_ema_ratio  macd_norm  \\\n",
      "0  46.259998    0.060158       0.058131            0.192156   0.022321   \n",
      "1  45.599998    0.033582       0.098122            0.137973   0.040848   \n",
      "2  45.520000   -0.129069       0.108398            0.000166   0.039339   \n",
      "3  46.779999    0.026751       0.092381            0.025211   0.034527   \n",
      "4  46.570000   -0.068911       0.089547           -0.039996   0.027710   \n",
      "\n",
      "   log_return_gc_close  \n",
      "0            -0.000490  \n",
      "1             0.004822  \n",
      "2            -0.019540  \n",
      "3            -0.000545  \n",
      "4             0.003376  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:205: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  master_df = master_df.groupby('ticker', group_keys=False).apply(calculate_indicators)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:268: FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "  master_df['funding_rate'] = master_df.groupby('ticker')['funding_rate'].fillna(method='ffill').fillna(0)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:268: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  master_df['funding_rate'] = master_df.groupby('ticker')['funding_rate'].fillna(method='ffill').fillna(0)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:311: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  master_df = master_df.groupby('ticker', group_keys=False).apply(create_additional_features)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51072/1487823124.py:317: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  master_df[col] = master_df[col].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ETL COMPLETO PARA NUEVO UNIVERSO DE CRYPTOS CON FUNDING RATES\n",
    "# ====================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import sqlalchemy\n",
    "# import pandas_ta as ta  # Comentado por conflicto con numpy\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "print(\"--- [INICIO] Construyendo DataFrame para el Nuevo Universo ---\")\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "new_ticker_list = [\n",
    "    'AVAX-USD', 'ATOM-USD', 'NEAR-USD', 'FTM-USD', 'UNI-USD',\n",
    "    'AAVE-USD', 'ALGO-USD', 'TRX-USD', 'XLM-USD', 'XTZ-USD'\n",
    "]\n",
    "start_date = \"2020-12-01\"\n",
    "end_date = \"2022-04-17\"\n",
    "\n",
    "# Mapeo de tickers de Yahoo Finance a s√≠mbolos de Binance para funding rates\n",
    "TICKER_TO_BINANCE = {\n",
    "    'AVAX-USD': 'AVAXUSDT',\n",
    "    'ATOM-USD': 'ATOMUSDT', \n",
    "    'NEAR-USD': 'NEARUSDT',\n",
    "    'FTM-USD': 'FTMUSDT',\n",
    "    'UNI-USD': 'UNIUSDT',\n",
    "    'AAVE-USD': 'AAVEUSDT',\n",
    "    'ALGO-USD': 'ALGOUSDT',\n",
    "    'TRX-USD': 'TRXUSDT',\n",
    "    'XLM-USD': 'XLMUSDT',\n",
    "    'XTZ-USD': 'XTZUSDT'\n",
    "}\n",
    "\n",
    "# --- PASO 1: Descargar Precios ---\n",
    "print(\"\\n -> Paso 1: Descargando datos de precios...\")\n",
    "try:\n",
    "    df_raw = yf.download(new_ticker_list, start=start_date, end=end_date, progress=False)\n",
    "    \n",
    "    if df_raw.empty:\n",
    "        raise Exception(\"No se descargaron datos de precios\")\n",
    "    \n",
    "    df_processed = df_raw.stack(level=1).reset_index()\n",
    "    df_processed = df_processed.rename(columns={\n",
    "        'Date': 'timestamp', 'Ticker': 'ticker', 'Open': 'open',\n",
    "        'High': 'high', 'Low': 'low', 'Close': 'close', 'Volume': 'volume'\n",
    "    })\n",
    "    \n",
    "    master_df = pd.DataFrame({\n",
    "        'timestamp': pd.to_datetime(df_processed['timestamp'], utc=True),\n",
    "        'ticker': df_processed['ticker'],\n",
    "        'open': df_processed['open'],\n",
    "        'high': df_processed['high'],\n",
    "        'low': df_processed['low'],\n",
    "        'close': df_processed['close'],\n",
    "        'volume': pd.to_numeric(df_processed['volume'], errors='coerce').fillna(0)\n",
    "    })\n",
    "    \n",
    "    master_df.dropna(subset=['close', 'timestamp', 'ticker'], inplace=True)\n",
    "    print(f\"‚úÖ Precios descargados ({master_df.shape[0]} filas).\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error descargando precios: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# --- PASO 2: Funci√≥n para obtener Funding Rates de Binance ---\n",
    "def get_funding_rate_history(symbol, start_timestamp, end_timestamp):\n",
    "    \"\"\"\n",
    "    Obtiene el historial de funding rates de Binance\n",
    "    \"\"\"\n",
    "    url = \"https://fapi.binance.com/fapi/v1/fundingRate\"\n",
    "    \n",
    "    funding_rates = []\n",
    "    current_start = start_timestamp\n",
    "    \n",
    "    while current_start < end_timestamp:\n",
    "        params = {\n",
    "            'symbol': symbol,\n",
    "            'startTime': current_start,\n",
    "            'endTime': min(current_start + (1000 * 8 * 60 * 60 * 1000), end_timestamp),  # Max 1000 records\n",
    "            'limit': 1000\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if not data:\n",
    "                break\n",
    "                \n",
    "            funding_rates.extend(data)\n",
    "            current_start = data[-1]['fundingTime'] + 1\n",
    "            time.sleep(0.1)  # Para evitar rate limiting\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error obteniendo funding rates para {symbol}: {e}\")\n",
    "            break\n",
    "    \n",
    "    return funding_rates\n",
    "\n",
    "print(\"\\n -> Paso 2: Descargando funding rates de Binance...\")\n",
    "\n",
    "# Convertir fechas a timestamps\n",
    "start_timestamp = int(pd.to_datetime(start_date).timestamp() * 1000)\n",
    "end_timestamp = int(pd.to_datetime(end_date).timestamp() * 1000)\n",
    "\n",
    "# Diccionario para almacenar funding rates por ticker\n",
    "funding_data = {}\n",
    "\n",
    "for yahoo_ticker, binance_symbol in TICKER_TO_BINANCE.items():\n",
    "    print(f\"  -> Descargando funding rates para {yahoo_ticker} ({binance_symbol})...\")\n",
    "    \n",
    "    try:\n",
    "        rates = get_funding_rate_history(binance_symbol, start_timestamp, end_timestamp)\n",
    "        \n",
    "        if rates:\n",
    "            df_funding = pd.DataFrame(rates)\n",
    "            df_funding['timestamp'] = pd.to_datetime(df_funding['fundingTime'], unit='ms', utc=True)\n",
    "            df_funding['funding_rate'] = pd.to_numeric(df_funding['fundingRate'])\n",
    "            df_funding['ticker'] = yahoo_ticker\n",
    "            \n",
    "            # Mantener solo las columnas necesarias\n",
    "            df_funding = df_funding[['timestamp', 'ticker', 'funding_rate']]\n",
    "            funding_data[yahoo_ticker] = df_funding\n",
    "            print(f\"    ‚úÖ {len(df_funding)} registros de funding rate obtenidos\")\n",
    "        else:\n",
    "            print(f\"    ‚ö†Ô∏è No se encontraron funding rates para {binance_symbol}\")\n",
    "            # Crear DataFrame vac√≠o con funding_rate = 0\n",
    "            dates = pd.date_range(start=start_date, end=end_date, freq='8H', tz='UTC')\n",
    "            df_funding = pd.DataFrame({\n",
    "                'timestamp': dates,\n",
    "                'ticker': yahoo_ticker,\n",
    "                'funding_rate': 0.0\n",
    "            })\n",
    "            funding_data[yahoo_ticker] = df_funding\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ùå Error con {yahoo_ticker}: {e}\")\n",
    "        # Crear DataFrame de respaldo con funding_rate = 0\n",
    "        dates = pd.date_range(start=start_date, end=end_date, freq='8H', tz='UTC')\n",
    "        df_funding = pd.DataFrame({\n",
    "            'timestamp': dates,\n",
    "            'ticker': yahoo_ticker,\n",
    "            'funding_rate': 0.0\n",
    "        })\n",
    "        funding_data[yahoo_ticker] = df_funding\n",
    "\n",
    "# Combinar todos los funding rates\n",
    "if funding_data:\n",
    "    all_funding_df = pd.concat(funding_data.values(), ignore_index=True)\n",
    "    print(f\"‚úÖ Funding rates procesados ({len(all_funding_df)} registros totales)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No se pudieron obtener funding rates, usando valores por defecto\")\n",
    "    all_funding_df = pd.DataFrame()\n",
    "\n",
    "# --- PASO 3: Calcular Indicadores T√©cnicos ---\n",
    "print(\"\\n -> Paso 3: Calculando indicadores t√©cnicos...\")\n",
    "master_df.sort_values(by=['ticker', 'timestamp'], inplace=True)\n",
    "\n",
    "def calculate_ema(prices, period):\n",
    "    \"\"\"Calcula EMA manualmente\"\"\"\n",
    "    alpha = 2 / (period + 1)\n",
    "    ema = np.zeros_like(prices)\n",
    "    ema[0] = prices[0]\n",
    "    \n",
    "    for i in range(1, len(prices)):\n",
    "        ema[i] = alpha * prices[i] + (1 - alpha) * ema[i-1]\n",
    "    \n",
    "    return ema\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calcula MACD manualmente\"\"\"\n",
    "    ema_fast = calculate_ema(prices, fast)\n",
    "    ema_slow = calculate_ema(prices, slow)\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    macd_signal = calculate_ema(macd_line, signal)\n",
    "    macd_hist = macd_line - macd_signal\n",
    "    \n",
    "    return macd_line, macd_signal, macd_hist\n",
    "\n",
    "def calculate_indicators(group):\n",
    "    \"\"\"Calcula los indicadores t√©cnicos necesarios\"\"\"\n",
    "    try:\n",
    "        prices = group['close'].values\n",
    "        \n",
    "        # Calcular MACD\n",
    "        macd_line, macd_signal, macd_hist = calculate_macd(prices)\n",
    "        group['macd'] = macd_line\n",
    "        group['macd_signal'] = macd_signal\n",
    "        group['macd_hist'] = macd_hist\n",
    "        \n",
    "        # Calcular EMA 26\n",
    "        group['ema_26'] = calculate_ema(prices, 26)\n",
    "        \n",
    "        return group\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error calculando indicadores para {group['ticker'].iloc[0]}: {e}\")\n",
    "        return group\n",
    "\n",
    "# Aplicar c√°lculo de indicadores (sin renombrar ya que usamos nombres correctos)\n",
    "master_df = master_df.groupby('ticker', group_keys=False).apply(calculate_indicators)\n",
    "\n",
    "print(\"‚úÖ Indicadores t√©cnicos calculados\")\n",
    "\n",
    "# --- PASO 4: Cargar Datos Macro desde BBDD ---\n",
    "print(\"\\n -> Paso 4: Cargando datos macro desde la base de datos...\")\n",
    "try:\n",
    "    # Configuraci√≥n de la base de datos\n",
    "    DB_USER = \"cryptonita_user\"\n",
    "    DB_PASSWORD = \"TIZavoltio999\" \n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5432\"\n",
    "    DB_NAME = \"cryptonita_db2\"\n",
    "    \n",
    "    db_url = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "    engine = sqlalchemy.create_engine(db_url)\n",
    "    \n",
    "    # Queries para datos macro\n",
    "    macro_queries = {\n",
    "        'macro_spy': \"SELECT timestamp, close AS spy_close FROM macro_spy\",\n",
    "        'macro_vix': \"SELECT timestamp, close AS vix_close FROM macro_vix\", \n",
    "        'macro_tnx': \"SELECT timestamp, close AS tnx_close FROM macro_tnx\",\n",
    "        'macro_dxy': \"SELECT timestamp, close AS dxy_close FROM macro_dx_y_nyb\",\n",
    "        'macro_gc': \"SELECT timestamp, close AS gc_close FROM macro_gc\",\n",
    "        'macro_cl': \"SELECT timestamp, close AS cl_close FROM macro_cl\"\n",
    "    }\n",
    "    \n",
    "    # Cargar datos macro\n",
    "    macro_dfs = {}\n",
    "    for name, query in macro_queries.items():\n",
    "        try:\n",
    "            df = pd.read_sql(query, engine)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True).dt.normalize()\n",
    "            macro_dfs[name] = df\n",
    "            print(f\"  ‚úÖ {name}: {len(df)} registros cargados\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö†Ô∏è Error cargando {name}: {e}\")\n",
    "    \n",
    "    # Unir datos macro al DataFrame principal\n",
    "    for name, df in macro_dfs.items():\n",
    "        master_df = pd.merge(master_df, df, on='timestamp', how='left')\n",
    "    \n",
    "    print(\"‚úÖ Datos macro unidos al DataFrame principal\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error con la base de datos: {e}\")\n",
    "    print(\"  -> Continuando sin datos macro (se llenar√°n con NaN)\")\n",
    "\n",
    "# --- PASO 5: Unir Funding Rates ---\n",
    "print(\"\\n -> Paso 5: Uniendo funding rates...\")\n",
    "if not all_funding_df.empty:\n",
    "    # Normalizar timestamp de funding rates para hacer join diario\n",
    "    all_funding_df['date'] = all_funding_df['timestamp'].dt.normalize()\n",
    "    master_df['date'] = master_df['timestamp'].dt.normalize()\n",
    "    \n",
    "    # Promediar funding rates por d√≠a si hay m√∫ltiples registros\n",
    "    daily_funding = all_funding_df.groupby(['ticker', 'date'])['funding_rate'].mean().reset_index()\n",
    "    \n",
    "    # Unir con el DataFrame principal\n",
    "    master_df = pd.merge(master_df, daily_funding, on=['ticker', 'date'], how='left')\n",
    "    master_df.drop('date', axis=1, inplace=True)\n",
    "    \n",
    "    # Rellenar valores faltantes de funding_rate\n",
    "    master_df['funding_rate'] = master_df.groupby('ticker')['funding_rate'].fillna(method='ffill').fillna(0)\n",
    "    \n",
    "    print(\"‚úÖ Funding rates unidos\")\n",
    "else:\n",
    "    master_df['funding_rate'] = 0.0\n",
    "    print(\"‚ö†Ô∏è Usando funding_rate = 0 por defecto\")\n",
    "\n",
    "# --- PASO 6: Crear Features Adicionales ---\n",
    "print(\"\\n -> Paso 6: Creando features adicionales...\")\n",
    "master_df.sort_values(by=['ticker', 'timestamp'], inplace=True)\n",
    "\n",
    "def create_additional_features(group):\n",
    "    \"\"\"Crea las features adicionales necesarias\"\"\"\n",
    "    try:\n",
    "        # Log return\n",
    "        group['log_return'] = np.log(group['close'] / group['close'].shift(1))\n",
    "        \n",
    "        # Volatilidad 7 d√≠as\n",
    "        group['volatility_7d'] = group['log_return'].rolling(window=7, min_periods=1).std()\n",
    "        \n",
    "        # Price to EMA ratio\n",
    "        if 'ema_26' in group.columns:\n",
    "            group['price_to_ema_ratio'] = (group['close'] / group['ema_26']) - 1\n",
    "        else:\n",
    "            group['price_to_ema_ratio'] = 0\n",
    "        \n",
    "        # MACD normalizado\n",
    "        if 'macd' in group.columns:\n",
    "            group['macd_norm'] = group['macd'] / group['close']\n",
    "        else:\n",
    "            group['macd_norm'] = 0\n",
    "            \n",
    "        # Log return del oro (si existe)\n",
    "        if 'gc_close' in group.columns:\n",
    "            group['log_return_gc_close'] = np.log(group['gc_close'] / group['gc_close'].shift(1))\n",
    "        else:\n",
    "            group['log_return_gc_close'] = 0\n",
    "            \n",
    "        return group\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error creando features para {group['ticker'].iloc[0]}: {e}\")\n",
    "        return group\n",
    "\n",
    "master_df = master_df.groupby('ticker', group_keys=False).apply(create_additional_features)\n",
    "\n",
    "# Forward-fill datos macro\n",
    "macro_cols = ['spy_close', 'vix_close', 'tnx_close', 'dxy_close', 'gc_close', 'cl_close']\n",
    "for col in macro_cols:\n",
    "    if col in master_df.columns:\n",
    "        master_df[col] = master_df[col].fillna(method='ffill')\n",
    "\n",
    "print(\"‚úÖ Features adicionales creadas\")\n",
    "\n",
    "# --- PASO 7: Aplicar Look-ahead Bias Correction ---\n",
    "print(\"\\n -> Paso 7: Aplicando correcci√≥n de look-ahead bias...\")\n",
    "feature_cols = ['macd_signal', 'macd_hist', 'funding_rate', 'spy_close', 'vix_close', \n",
    "                'tnx_close', 'dxy_close', 'gc_close', 'cl_close', 'log_return', \n",
    "                'volatility_7d', 'price_to_ema_ratio', 'macd_norm', 'log_return_gc_close']\n",
    "\n",
    "existing_feature_cols = [col for col in feature_cols if col in master_df.columns]\n",
    "master_df[existing_feature_cols] = master_df.groupby('ticker')[existing_feature_cols].shift(1)\n",
    "\n",
    "# --- PASO 8: Filtrar Solo las Columnas Necesarias ---\n",
    "target_columns = ['close', 'macd_signal', 'macd_hist', 'funding_rate', 'spy_close', \n",
    "                 'vix_close', 'tnx_close', 'dxy_close', 'gc_close', 'cl_close', \n",
    "                 'log_return', 'volatility_7d', 'price_to_ema_ratio', 'macd_norm', \n",
    "                 'log_return_gc_close']\n",
    "\n",
    "# Mantener tambi√©n timestamp y ticker para referencia\n",
    "final_columns = ['timestamp', 'ticker'] + target_columns\n",
    "available_columns = [col for col in final_columns if col in master_df.columns]\n",
    "\n",
    "final_df = master_df[available_columns].copy()\n",
    "\n",
    "# Eliminar filas con NaN\n",
    "final_df.dropna(inplace=True)\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"‚úÖ Look-ahead bias corregido y columnas filtradas\")\n",
    "\n",
    "# --- PASO 9: Guardar Resultado ---\n",
    "print(\"\\n -> Paso 9: Guardando DataFrame final...\")\n",
    "output_dir = 'dataframes/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_path = os.path.join(output_dir, 'master_df_new_universe_complete.parquet')\n",
    "final_df.to_parquet(file_path)\n",
    "\n",
    "print(f\"\\nüéâ ¬°√âXITO COMPLETO!\")\n",
    "print(f\"üìÅ DataFrame guardado en: {file_path}\")\n",
    "print(f\"üìä Shape final: {final_df.shape}\")\n",
    "print(f\"üìã Columnas finales: {list(final_df.columns)}\")\n",
    "\n",
    "# Mostrar resumen por ticker\n",
    "print(f\"\\n--- RESUMEN POR TICKER ---\")\n",
    "summary = final_df.groupby('ticker').agg({\n",
    "    'close': 'count',\n",
    "    'timestamp': ['min', 'max']\n",
    "}).round(2)\n",
    "summary.columns = ['Records', 'Start_Date', 'End_Date']\n",
    "print(summary)\n",
    "\n",
    "print(f\"\\n--- MUESTRA DE DATOS ---\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cad2d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Verificando 'master_df_new_universe_complete.parquet' ---\n",
      "‚úÖ DataFrame cargado con √©xito desde 'dataframes/master_df_new_universe_complete.parquet'\n",
      "\n",
      "========================= AUDITOR√çA R√ÅPIDA =========================\n",
      " -> Shape del DataFrame: (2710, 17)\n",
      "\n",
      " -> Tickers encontrados (10): ['AAVE-USD', 'ALGO-USD', 'ATOM-USD', 'AVAX-USD', 'FTM-USD', 'NEAR-USD', 'TRX-USD', 'UNI-USD', 'XLM-USD', 'XTZ-USD']\n",
      "\n",
      " -> Columnas presentes (primeras 15):\n",
      "['timestamp', 'ticker', 'close', 'macd_signal', 'macd_hist', 'funding_rate', 'spy_close', 'vix_close', 'tnx_close', 'dxy_close', 'gc_close', 'cl_close', 'log_return', 'volatility_7d', 'price_to_ema_ratio']\n",
      "\n",
      " -> Conteo de valores nulos por columna:\n",
      "timestamp              0\n",
      "ticker                 0\n",
      "close                  0\n",
      "macd_signal            0\n",
      "macd_hist              0\n",
      "funding_rate           0\n",
      "spy_close              0\n",
      "vix_close              0\n",
      "tnx_close              0\n",
      "dxy_close              0\n",
      "gc_close               0\n",
      "cl_close               0\n",
      "log_return             0\n",
      "volatility_7d          0\n",
      "price_to_ema_ratio     0\n",
      "macd_norm              0\n",
      "log_return_gc_close    0\n",
      "\n",
      "--- [FIN] Verificaci√≥n completada. ---\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# CELDA 2: VERIFICACI√ìN DEL NUEVO DATAFRAME COMPLETO\n",
    "# ====================================================================\n",
    "import pandas as pd\n",
    "\n",
    "print(\"--- [INICIO] Verificando 'master_df_new_universe_complete.parquet' ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Cargar el DataFrame que has creado\n",
    "    data_path = 'dataframes/master_df_new_universe_complete.parquet'\n",
    "    df_new_universe = pd.read_parquet(data_path)\n",
    "    print(f\"‚úÖ DataFrame cargado con √©xito desde '{data_path}'\")\n",
    "\n",
    "    # 2. Auditor√≠a R√°pida de los Datos\n",
    "    print(\"\\n\" + \"=\"*25 + \" AUDITOR√çA R√ÅPIDA \" + \"=\"*25)\n",
    "    print(f\" -> Shape del DataFrame: {df_new_universe.shape}\")\n",
    "    \n",
    "    tickers_encontrados = sorted(df_new_universe['ticker'].unique())\n",
    "    print(f\"\\n -> Tickers encontrados ({len(tickers_encontrados)}): {tickers_encontrados}\")\n",
    "    \n",
    "    print(\"\\n -> Columnas presentes (primeras 15):\")\n",
    "    print(df_new_universe.columns[:15].tolist())\n",
    "    \n",
    "    print(\"\\n -> Conteo de valores nulos por columna:\")\n",
    "    print(df_new_universe.isnull().sum().to_string())\n",
    "    \n",
    "    print(\"\\n--- [FIN] Verificaci√≥n completada. ---\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: No se pudo encontrar el archivo en la ruta '{data_path}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERROR inesperado durante la carga o verificaci√≥n: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87de7d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Ejecutando backtest de generalizaci√≥n en el nuevo universo ---\n",
      "‚úÖ Modelo Maestro cargado con √©xito.\n",
      "\n",
      "==================== PROCESANDO TICKER: AAVE-USD ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> RESULTADOS PARA AAVE-USD: Total Return: 409.06%, Win Rate: 72.00%, Trades: 25\n",
      "\n",
      "==================== PROCESANDO TICKER: ALGO-USD ====================\n",
      " -> RESULTADOS PARA ALGO-USD: Total Return: 298.41%, Win Rate: 79.17%, Trades: 25\n",
      "\n",
      "==================== PROCESANDO TICKER: ATOM-USD ====================\n",
      " -> RESULTADOS PARA ATOM-USD: Total Return: 477.59%, Win Rate: 80.77%, Trades: 27\n",
      "\n",
      "==================== PROCESANDO TICKER: AVAX-USD ====================\n",
      " -> RESULTADOS PARA AVAX-USD: Total Return: 101.80%, Win Rate: 73.91%, Trades: 23\n",
      "\n",
      "==================== PROCESANDO TICKER: FTM-USD ====================\n",
      " -> RESULTADOS PARA FTM-USD: Total Return: 163.27%, Win Rate: 66.67%, Trades: 25\n",
      "\n",
      "==================== PROCESANDO TICKER: NEAR-USD ====================\n",
      " -> RESULTADOS PARA NEAR-USD: Total Return: 341.55%, Win Rate: 79.17%, Trades: 24\n",
      "\n",
      "==================== PROCESANDO TICKER: TRX-USD ====================\n",
      " -> RESULTADOS PARA TRX-USD: Total Return: 199.67%, Win Rate: 82.61%, Trades: 23\n",
      "\n",
      "==================== PROCESANDO TICKER: UNI-USD ====================\n",
      " -> RESULTADOS PARA UNI-USD: Total Return: -80.75%, Win Rate: 48.72%, Trades: 39\n",
      "\n",
      "==================== PROCESANDO TICKER: XLM-USD ====================\n",
      " -> RESULTADOS PARA XLM-USD: Total Return: 278.96%, Win Rate: 69.23%, Trades: 26\n",
      "\n",
      "==================== PROCESANDO TICKER: XTZ-USD ====================\n",
      " -> RESULTADOS PARA XTZ-USD: Total Return: 246.38%, Win Rate: 73.08%, Trades: 27\n",
      "\n",
      "========================= INFORME DE GENERALIZACI√ìN (OUT-OF-SAMPLE) =========================\n",
      "          Total Return [%]  Max Drawdown [%]  Win Rate [%]  Total Trades  \\\n",
      "AAVE-USD        409.060722         17.359538     72.000000            25   \n",
      "ALGO-USD        298.405155         29.340959     79.166667            25   \n",
      "ATOM-USD        477.592891         17.146097     80.769231            27   \n",
      "AVAX-USD        101.801480         21.235801     73.913043            23   \n",
      "FTM-USD         163.270924         20.011245     66.666667            25   \n",
      "NEAR-USD        341.549009         27.878390     79.166667            24   \n",
      "TRX-USD         199.665222         21.409135     82.608696            23   \n",
      "UNI-USD         -80.747685         91.571057     48.717949            39   \n",
      "XLM-USD         278.955971         24.253294     69.230769            26   \n",
      "XTZ-USD         246.376022         20.102356     73.076923            27   \n",
      "\n",
      "          Sharpe Ratio  Sortino Ratio  \n",
      "AAVE-USD      3.023120       8.563388  \n",
      "ALGO-USD      2.756308       7.259795  \n",
      "ATOM-USD      3.359827       9.728461  \n",
      "AVAX-USD      2.005905       3.687469  \n",
      "FTM-USD       2.502680       5.513634  \n",
      "NEAR-USD      3.218549       7.687984  \n",
      "TRX-USD       3.100337       6.231332  \n",
      "UNI-USD       0.969334       2.685863  \n",
      "XLM-USD       2.440471       7.018592  \n",
      "XTZ-USD       2.812696       6.005442  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/User/Library/CloudStorage/GoogleDrive-ignaciovct99@gmail.com/Mi unidad/Documentos/PROYECTOS/CRYPTONITA/cryptonita/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# CELDA 3: EJECUCI√ìN DEL BACKTEST DE GENERALIZACI√ìN\n",
    "# ====================================================================\n",
    "import vectorbt as vbt\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- [INICIO] Ejecutando backtest de generalizaci√≥n en el nuevo universo ---\")\n",
    "\n",
    "# --- 1. Cargar el Modelo Maestro ---\n",
    "try:\n",
    "    model_package = joblib.load('models/ULTRA_MODEL_PACKAGE.joblib')\n",
    "    primary_model = model_package['primary_model_pipeline']\n",
    "    meta_model = model_package['meta_model']\n",
    "    optimal_threshold = model_package['optimal_threshold']\n",
    "    model_features_list = model_package['feature_list']\n",
    "    print(\"‚úÖ Modelo Maestro cargado con √©xito.\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå ERROR: No se pudo cargar el archivo del modelo. Error: {e}\")\n",
    "\n",
    "# --- 2. Preparar los datos finales ---\n",
    "# Usamos el df_new_universe verificado en la celda anterior\n",
    "X_oos = df_new_universe.copy()\n",
    "if 'timestamp' in X_oos.columns:\n",
    "    X_oos.set_index('timestamp', inplace=True)\n",
    "\n",
    "all_tickers_oos = X_oos['ticker'].unique()\n",
    "all_stats_oos = []\n",
    "\n",
    "# --- 3. Bucle de Predicci√≥n y Backtesting por Ticker ---\n",
    "for ticker in all_tickers_oos:\n",
    "    print(f\"\\n{'='*20} PROCESANDO TICKER: {ticker} {'='*20}\")\n",
    "    \n",
    "    # Seleccionamos los datos del ticker y nos aseguramos de tener solo las 15 features\n",
    "    original_model_features = [col.split('__')[1] for col in model_features_list]\n",
    "    ticker_X_oos = X_oos[X_oos['ticker'] == ticker][original_model_features]\n",
    "    \n",
    "    if ticker_X_oos.empty:\n",
    "        continue\n",
    "\n",
    "    # --- L√ìGICA DE PREDICCI√ìN (SIN ENTRENAMIENTO) ---\n",
    "    primary_test_proba = primary_model.predict_proba(ticker_X_oos)\n",
    "    primary_test_preds = np.argmax(primary_test_proba, axis=1)\n",
    "    \n",
    "    X_meta_test = pd.DataFrame({'primary_model_prob': primary_test_proba.max(axis=1)})\n",
    "    meta_test_probs = meta_model.predict_proba(X_meta_test)[:, 1]\n",
    "    \n",
    "    entries = (meta_test_probs >= optimal_threshold)\n",
    "    buy_signals = pd.Series((primary_test_preds == 1) & entries, index=ticker_X_oos.index)\n",
    "    sell_signals = pd.Series((primary_test_preds == 0) & entries, index=ticker_X_oos.index)\n",
    "    \n",
    "    if buy_signals.sum() == 0 and sell_signals.sum() == 0:\n",
    "        print(f\" -> No se generaron operaciones para {ticker}.\")\n",
    "        continue\n",
    "\n",
    "    # --- BACKTEST ---\n",
    "    # Necesitamos los datos OHLC del DataFrame original para el backtest\n",
    "    price_data_for_pf = df_new_universe[df_new_universe['ticker'] == ticker].set_index('timestamp')\n",
    "    \n",
    "    wf_portfolio = vbt.Portfolio.from_signals(\n",
    "        close=price_data_for_pf['close'], \n",
    "        entries=buy_signals,\n",
    "        exits=sell_signals,\n",
    "        fees=0.002, sl_stop=0.05, tp_stop=0.05, init_cash=100000, freq='D')\n",
    "    \n",
    "    ticker_stats = wf_portfolio.stats()\n",
    "    ticker_stats.name = ticker\n",
    "    all_stats_oos.append(ticker_stats)\n",
    "    print(f\" -> RESULTADOS PARA {ticker}: Total Return: {ticker_stats['Total Return [%]']:.2f}%, Win Rate: {ticker_stats['Win Rate [%]']:.2f}%, Trades: {ticker_stats['Total Trades']}\")\n",
    "\n",
    "# --- INFORME FINAL ---\n",
    "print(f\"\\n{'='*25} INFORME DE GENERALIZACI√ìN (OUT-OF-SAMPLE) {'='*25}\")\n",
    "if not all_stats_oos:\n",
    "    print(\"No se generaron estad√≠sticas.\")\n",
    "else:\n",
    "    final_stats_df_oos = pd.DataFrame(all_stats_oos)\n",
    "    print(final_stats_df_oos[['Total Return [%]', 'Max Drawdown [%]', 'Win Rate [%]', 'Total Trades', 'Sharpe Ratio', 'Sortino Ratio']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptonita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
