{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f66c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO DE LA CONSTRUCCIÓN DEL DataFrame Maestro Final] ---\n",
      " -> Paso 1: Extrayendo TODAS las tablas de la base de datos...\n",
      " -> Tablas extraídas con éxito.\n",
      "\n",
      " -> Paso 2: Transformando y uniendo los datos...\n",
      " -> Gestionando valores nulos...\n",
      " -> Calculando características financieras avanzadas...\n",
      " -> Aplicando retraso (shift)...\n",
      " -> Transformación completada.\n",
      "\n",
      " -> Paso 3: Realizando comprobación de sanidad y guardando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51120/4138816404.py:69: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df['sentiment_score'].fillna(0, inplace=True)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51120/4138816404.py:70: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df['pattern_name'].fillna('no_pattern', inplace=True)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51120/4138816404.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df['pattern_score'].fillna(0, inplace=True)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51120/4138816404.py:72: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  master_df['funding_rate'].fillna(0, inplace=True)\n",
      "/var/folders/z_/rcq9bsy13fzbphk_82m0p03r0000gn/T/ipykernel_51120/4138816404.py:81: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  master_df = master_df.groupby('ticker', group_keys=False).apply(apply_feature_engineering)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "¡Alerta! El DataFrame tiene muy pocas filas (0).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 96\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m -> Paso 3: Realizando comprobación de sanidad y guardando...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m master_df.isnull().sum().sum() == \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m¡Alerta! Aún quedan valores nulos.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m master_df.shape[\u001b[32m0\u001b[39m] > \u001b[32m100\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m¡Alerta! El DataFrame tiene muy pocas filas (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaster_df.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Comprobación de sanidad superada.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m output_dir = \u001b[33m'\u001b[39m\u001b[33mdataframes/\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: ¡Alerta! El DataFrame tiene muy pocas filas (0)."
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# NOTEBOOK 01: CONSTRUCCIÓN DEL DATAFRAME MAESTRO FINAL (ETL)\n",
    "# Misión: Extraer, transformar y cargar todos los datos en un único\n",
    "# fichero Parquet limpio, robusto y libre de look-ahead bias.\n",
    "# ====================================================================\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"--- [INICIO DE LA CONSTRUCCIÓN DEL DataFrame Maestro Final] ---\")\n",
    "\n",
    "# --- 1. EXTRACCIÓN (EXTRACT) ---\n",
    "print(\" -> Paso 1: Extrayendo TODAS las tablas de la base de datos...\")\n",
    "try:\n",
    "    DB_USER = \"cryptonita_user\"\n",
    "    DB_PASSWORD = \"TIZavoltio999\"\n",
    "    DB_HOST = \"localhost\"\n",
    "    DB_PORT = \"5432\"\n",
    "    DB_NAME = \"cryptonita_db2\"\n",
    "    db_url = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "    engine = sqlalchemy.create_engine(db_url)\n",
    "    \n",
    "    # Se leen todas las tablas, sin quitar ninguna\n",
    "    tables_to_load = {\n",
    "        'asset_metrics': \"SELECT * FROM asset_metrics\",\n",
    "        'technical_indicators': \"SELECT * FROM technical_indicators\",\n",
    "        'sentiment_metrics': \"SELECT * FROM sentiment_metrics\",\n",
    "        'candle_patterns': \"SELECT * FROM candle_patterns\",\n",
    "        'derivatives_funding_rates': \"SELECT * FROM derivatives_funding_rates\",\n",
    "        'macro_spy': \"SELECT timestamp, close AS spy_close FROM macro_spy\",\n",
    "        'macro_vix': \"SELECT timestamp, close AS vix_close FROM macro_vix\",\n",
    "        'macro_tnx': \"SELECT timestamp, close AS tnx_close FROM macro_tnx\",\n",
    "        'macro_dxy': \"SELECT timestamp, close AS dxy_close FROM macro_dx_y_nyb\",\n",
    "        'macro_gc': \"SELECT timestamp, close AS gc_close FROM macro_gc\",\n",
    "        'macro_cl': \"SELECT timestamp, close AS cl_close FROM macro_cl\",\n",
    "    }\n",
    "    \n",
    "    dataframes = {name: pd.read_sql(query, engine) for name, query in tables_to_load.items()}\n",
    "    print(\" -> Tablas extraídas con éxito.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"❌ Error durante la extracción de datos: {e}\")\n",
    "\n",
    "# --- 2. TRANSFORMACIÓN (TRANSFORM) ---\n",
    "print(\"\\n -> Paso 2: Transformando y uniendo los datos...\")\n",
    "\n",
    "# 2.1: Asegurar tipos de datos de timestamp\n",
    "for name, df in dataframes.items():\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True).dt.normalize()\n",
    "\n",
    "# 2.2: Unir todas las tablas (sin excepciones)\n",
    "master_df = dataframes['asset_metrics']\n",
    "tables_by_ticker = ['technical_indicators', 'sentiment_metrics', 'candle_patterns', 'derivatives_funding_rates']\n",
    "for name in tables_by_ticker:\n",
    "    master_df = pd.merge(master_df, dataframes[name], on=['timestamp', 'ticker'], how='left')\n",
    "\n",
    "tables_by_date = ['macro_spy', 'macro_vix', 'macro_tnx', 'macro_dxy', 'macro_gc', 'macro_cl']\n",
    "for name in tables_by_date:\n",
    "    master_df = pd.merge(master_df, dataframes[name], on='timestamp', how='left')\n",
    "\n",
    "# 2.3: Manejo de nulos (lógica original completa)\n",
    "print(\" -> Gestionando valores nulos...\")\n",
    "macro_cols = ['spy_close', 'vix_close', 'tnx_close', 'dxy_close', 'gc_close', 'cl_close']\n",
    "master_df.sort_values(by=['timestamp'], inplace=True)\n",
    "master_df[macro_cols] = master_df[macro_cols].ffill()\n",
    "master_df['sentiment_score'].fillna(0, inplace=True)\n",
    "master_df['pattern_name'].fillna('no_pattern', inplace=True)\n",
    "master_df['pattern_score'].fillna(0, inplace=True)\n",
    "master_df['funding_rate'].fillna(0, inplace=True)\n",
    "\n",
    "# 2.4: Ingeniería de características\n",
    "print(\" -> Calculando características financieras avanzadas...\")\n",
    "master_df.sort_values(by=['ticker', 'timestamp'], inplace=True)\n",
    "def apply_feature_engineering(group):\n",
    "    group['log_return'] = np.log(group['close'] / group['close'].shift(1))\n",
    "    group['volatility_7d'] = group['log_return'].rolling(7).std()\n",
    "    return group\n",
    "master_df = master_df.groupby('ticker', group_keys=False).apply(apply_feature_engineering)\n",
    "\n",
    "# 2.5: CORRECCIÓN DE LOOK-AHEAD BIAS\n",
    "feature_cols = master_df.columns.drop(['timestamp', 'ticker', 'open', 'high', 'low', 'close', 'volume'])\n",
    "print(\" -> Aplicando retraso (shift)...\")\n",
    "master_df[feature_cols] = master_df.groupby('ticker')[feature_cols].shift(1)\n",
    "\n",
    "# Limpieza final de NaNs\n",
    "master_df.dropna(inplace=True)\n",
    "master_df.reset_index(drop=True, inplace=True)\n",
    "print(\" -> Transformación completada.\")\n",
    "\n",
    "# --- 3. SANITY CHECK Y CARGA (LOAD) ---\n",
    "print(\"\\n -> Paso 3: Realizando comprobación de sanidad y guardando...\")\n",
    "assert master_df.isnull().sum().sum() == 0, \"¡Alerta! Aún quedan valores nulos.\"\n",
    "assert master_df.shape[0] > 100, f\"¡Alerta! El DataFrame tiene muy pocas filas ({master_df.shape[0]}).\"\n",
    "print(\"✅ Comprobación de sanidad superada.\")\n",
    "\n",
    "output_dir = 'dataframes/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# --- CAMBIO CLAVE: Nombre del archivo de salida ---\n",
    "file_path = os.path.join(output_dir, 'master_df_new_universe.parquet')\n",
    "\n",
    "master_df.to_parquet(file_path)\n",
    "\n",
    "print(f\"✅ ¡Éxito! Tu DataFrame Maestro para el NUEVO UNIVERSO ha sido guardado en: {file_path}\")\n",
    "print(f\" -> Forma final del DataFrame: {master_df.shape}\")\n",
    "print(\"\\n--- [FIN DE LA CONSTRUCCIÓN] ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptonita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
