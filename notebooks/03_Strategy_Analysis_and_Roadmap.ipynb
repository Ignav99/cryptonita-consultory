{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf71134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Cargando y Auditando Artefactos del Proyecto ---\n",
      "✅ [1/3] DataFrame completo cargado desde 'dataframes/data_with_target.parquet' (Shape: (5391, 45))\n",
      "✅ [2/3] Lista de características importantes cargada desde 'important_features.json' (15 features)\n",
      "✅ [3/3] Paquete de modelos cargado desde 'models/final_strategy_package.joblib'\n",
      "\n",
      "========================= AUDITORÍA DEL ESTADO DEL PROYECTO =========================\n",
      "\n",
      "--- A. Consistencia de Características ---\n",
      "Las 15 características que nuestro modelo utiliza son:\n",
      "['close', 'macd_signal', 'macd_hist', 'funding_rate', 'spy_close', 'vix_close', 'tnx_close', 'dxy_close', 'gc_close', 'cl_close', 'log_return', 'volatility_7d', 'price_to_ema_ratio', 'macd_norm', 'log_return_gc_close']\n",
      "\n",
      "--- B. Auditoría del Pipeline Guardado ---\n",
      "Pipeline Primario encontrado en el paquete:\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
      "                                                  ['close', 'macd_signal',\n",
      "                                                   'macd_hist', 'funding_rate',\n",
      "                                                   'spy_close', 'vix_close',\n",
      "                                                   'tnx_close', 'dxy_close',\n",
      "                                                   'gc_close', 'cl_close',\n",
      "                                                   'log_return',\n",
      "                                                   'volatility_7d',\n",
      "                                                   'price_to_ema_ratio',\n",
      "                                                   'macd_norm',\n",
      "                                                   'log_return_gc_close']),\n",
      "                                                 ('cat',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                sparse_output=False),\n",
      "                                                  [])])),\n",
      "                ('pca', PCA(n_components=0.95)),\n",
      "                ('classifier',\n",
      "                 LGBMClassifier(class_weight='balanced', objective='binary',\n",
      "                                random_state=42))])\n",
      "\n",
      "--- C. Construcción del DataFrame Final de Trabajo ---\n",
      "A partir de ahora, trabajaremos con estos DataFrames auditados:\n",
      " -> X_final_auditado (Shape: (5391, 21))\n",
      " -> y_final_auditado (Shape: (5391,))\n",
      "\n",
      "--- [FIN] Auditoría completada. El estado base del proyecto ha sido cargado en memoria. ---\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# CELDA 1: CARGA Y AUDITORÍA DE ARTEFACTOS DEL PROYECTO\n",
    "# ====================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"--- [INICIO] Cargando y Auditando Artefactos del Proyecto ---\")\n",
    "\n",
    "# --- 1. Cargar los tres artefactos clave ---\n",
    "try:\n",
    "    # Artefacto 1: El DataFrame con todas las características y el target\n",
    "    data_path = 'dataframes/data_with_target.parquet'\n",
    "    df_completo = pd.read_parquet(data_path)\n",
    "    print(f\"✅ [1/3] DataFrame completo cargado desde '{data_path}' (Shape: {df_completo.shape})\")\n",
    "\n",
    "    # Artefacto 2: La lista de características importantes seleccionadas por RFECV\n",
    "    features_path = 'important_features.json'\n",
    "    with open(features_path, 'r') as f:\n",
    "        important_feature_names = json.load(f)\n",
    "    print(f\"✅ [2/3] Lista de características importantes cargada desde '{features_path}' ({len(important_feature_names)} features)\")\n",
    "\n",
    "    # Artefacto 3: El paquete de estrategia con los modelos entrenados\n",
    "    package_path = 'models/final_strategy_package.joblib'\n",
    "    strategy_package = joblib.load(package_path)\n",
    "    print(f\"✅ [3/3] Paquete de modelos cargado desde '{package_path}'\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ ERROR: No se pudo encontrar un archivo esencial: {e}\")\n",
    "    print(\"   -> Asegúrate de haber ejecutado los notebooks 01 y 02 completamente y de que los archivos existen.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR inesperado durante la carga: {e}\")\n",
    "\n",
    "\n",
    "# --- 2. Auditoría del Estado Cargado ---\n",
    "print(\"\\n\" + \"=\"*25 + \" AUDITORÍA DEL ESTADO DEL PROYECTO \" + \"=\"*25)\n",
    "\n",
    "# A. Consistencia de las Características\n",
    "print(\"\\n--- A. Consistencia de Características ---\")\n",
    "original_cols_to_keep = [col.split('__')[1] for col in important_feature_names]\n",
    "print(f\"Las {len(original_cols_to_keep)} características que nuestro modelo utiliza son:\")\n",
    "print(original_cols_to_keep)\n",
    "\n",
    "# B. Auditoría del Pipeline Guardado\n",
    "print(\"\\n--- B. Auditoría del Pipeline Guardado ---\")\n",
    "loaded_pipeline = strategy_package.get('primary_model_pipeline')\n",
    "if loaded_pipeline:\n",
    "    print(\"Pipeline Primario encontrado en el paquete:\")\n",
    "    print(loaded_pipeline)\n",
    "else:\n",
    "    print(\"❌ No se encontró 'primary_model_pipeline' en el paquete guardado.\")\n",
    "\n",
    "# C. Creación del DataFrame Final para Backtesting (La \"Verdad Absoluta\")\n",
    "print(\"\\n--- C. Construcción del DataFrame Final de Trabajo ---\")\n",
    "structural_cols = ['ticker', 'timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
    "final_cols_to_keep = list(set(original_cols_to_keep + structural_cols))\n",
    "X_final_auditado = df_completo[final_cols_to_keep].copy()\n",
    "y_final_auditado = df_completo['target'].copy()\n",
    "\n",
    "print(\"A partir de ahora, trabajaremos con estos DataFrames auditados:\")\n",
    "print(f\" -> X_final_auditado (Shape: {X_final_auditado.shape})\")\n",
    "print(f\" -> y_final_auditado (Shape: {y_final_auditado.shape})\")\n",
    "\n",
    "\n",
    "print(\"\\n--- [FIN] Auditoría completada. El estado base del proyecto ha sido cargado en memoria. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b5f83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Prueba de Fuego para el Primer Split de BTC-USD (CORREGIDA) ---\n",
      "📊 Diagnóstico inicial:\n",
      "   - X_final_auditado shape: (5391, 21)\n",
      "   - y_final_auditado shape: (5391,)\n",
      "   - X_final_auditado index: <class 'pandas.core.indexes.range.RangeIndex'>\n",
      "   - y_final_auditado index: <class 'pandas.core.indexes.range.RangeIndex'>\n",
      "🔍 Filtrado por ticker 'BTC-USD':\n",
      "   - Filas encontradas: 459\n",
      "   - ticker_X shape: (459, 19)\n",
      "   - ticker_y shape después del filtrado: (459,)\n",
      "✅ Datos sincronizados correctamente:\n",
      "   - ticker_X shape: (459, 19)\n",
      "   - ticker_y shape: (459,)\n",
      "   - Índices alineados: True\n",
      "✅ Splits creados correctamente:\n",
      "   - train_X_split_1: (189, 19)\n",
      "   - train_y_split_1: (189,)\n",
      "   - test_X_split_1: (63, 19)\n",
      "\n",
      "🔥 EJECUTANDO PRUEBA DE FUEGO...\n",
      "   📊 Input data: train_X=(189, 19), train_y=(189,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 182 filas válidas de 189 originales\n",
      "   📊 Distribución de clases: {0: 95, 1: 87}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "\n",
      "============================================================\n",
      "🎉 RESULTADO: PRUEBA SUPERADA\n",
      "============================================================\n",
      "✅ La función se ejecutó sin errores\n",
      "📊 Señales generadas en el primer split:\n",
      "   - Compras: 0\n",
      "   - Ventas: 0\n",
      "   - Total entradas: 0\n",
      "   - Cobertura: 0.0%\n",
      "\n",
      "🏁 Prueba de fuego completada.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# CELDA 2: PRUEBA DE FUEGO CORREGIDA (LÓGICA DE ENTRENAMIENTO AISLADA)\n",
    "# ====================================================================\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- [INICIO] Prueba de Fuego para el Primer Split de BTC-USD (CORREGIDA) ---\")\n",
    "\n",
    "# --- 1. PREPARACIÓN ROBUSTA DE DATOS ---\n",
    "ticker_de_prueba = 'BTC-USD'\n",
    "\n",
    "# ✅ PASO 1: Verificar la estructura de los datos\n",
    "print(f\"📊 Diagnóstico inicial:\")\n",
    "print(f\"   - X_final_auditado shape: {X_final_auditado.shape}\")\n",
    "print(f\"   - y_final_auditado shape: {y_final_auditado.shape}\")\n",
    "print(f\"   - X_final_auditado index: {type(X_final_auditado.index)}\")\n",
    "print(f\"   - y_final_auditado index: {type(y_final_auditado.index)}\")\n",
    "\n",
    "# ✅ PASO 2: Sincronización correcta de índices\n",
    "# Asegurarnos de que timestamp sea el índice en ambos DataFrames\n",
    "if 'timestamp' in X_final_auditado.columns:\n",
    "    X_final_auditado = X_final_auditado.set_index('timestamp')\n",
    "\n",
    "# Si y_final_auditado no tiene timestamp como índice, necesitamos alinearlo correctamente\n",
    "if not isinstance(y_final_auditado.index, pd.DatetimeIndex):\n",
    "    # Asumir que y_final_auditado debe tener el mismo índice que X_final_auditado\n",
    "    # pero solo para las filas que realmente existen\n",
    "    common_index = X_final_auditado.index\n",
    "    if len(y_final_auditado) == len(common_index):\n",
    "        y_final_auditado.index = common_index\n",
    "    else:\n",
    "        raise ValueError(f\"Incompatibilidad de datos: X tiene {len(X_final_auditado)} filas, \"\n",
    "                        f\"pero y tiene {len(y_final_auditado)} filas. \"\n",
    "                        f\"Los datos deben estar perfectamente alineados.\")\n",
    "\n",
    "# ✅ PASO 3: Filtrado por ticker con verificación CORRECTA\n",
    "ticker_mask = X_final_auditado['ticker'] == ticker_de_prueba\n",
    "ticker_X = X_final_auditado[ticker_mask].drop(columns=['ticker'])\n",
    "\n",
    "print(f\"🔍 Filtrado por ticker '{ticker_de_prueba}':\")\n",
    "print(f\"   - Filas encontradas: {ticker_mask.sum()}\")\n",
    "print(f\"   - ticker_X shape: {ticker_X.shape}\")\n",
    "\n",
    "# ⚠️ CLAVE: Filtrar y_final_auditado usando la MISMA MÁSCARA\n",
    "# No usar índices porque pueden estar duplicados entre tickers\n",
    "ticker_y = y_final_auditado[ticker_mask]\n",
    "\n",
    "print(f\"   - ticker_y shape después del filtrado: {ticker_y.shape}\")\n",
    "\n",
    "# Verificar que ambos tienen exactamente las mismas filas\n",
    "if len(ticker_X) != len(ticker_y):\n",
    "    print(f\"❌ ERROR: Después del filtrado por máscara:\")\n",
    "    print(f\"   - ticker_X: {len(ticker_X)} filas\")\n",
    "    print(f\"   - ticker_y: {len(ticker_y)} filas\")\n",
    "    \n",
    "    # Diagnóstico adicional\n",
    "    print(f\"📊 Análisis de índices:\")\n",
    "    print(f\"   - X_final_auditado index duplicates: {X_final_auditado.index.duplicated().sum()}\")\n",
    "    print(f\"   - y_final_auditado index duplicates: {y_final_auditado.index.duplicated().sum()}\")\n",
    "    \n",
    "    raise ValueError(f\"El filtrado por máscara no funcionó correctamente. \"\n",
    "                    f\"Esto indica que X_final_auditado e y_final_auditado no están \"\n",
    "                    f\"perfectamente alineados fila por fila.\")\n",
    "\n",
    "# ✅ PASO 4: Verificación final de alineación\n",
    "assert len(ticker_X) == len(ticker_y), f\"Desalineación: X={len(ticker_X)}, y={len(ticker_y)}\"\n",
    "assert (ticker_X.index == ticker_y.index).all(), \"Los índices no coinciden exactamente\"\n",
    "\n",
    "print(f\"✅ Datos sincronizados correctamente:\")\n",
    "print(f\"   - ticker_X shape: {ticker_X.shape}\")\n",
    "print(f\"   - ticker_y shape: {ticker_y.shape}\")\n",
    "print(f\"   - Índices alineados: {(ticker_X.index == ticker_y.index).all()}\")\n",
    "\n",
    "# ✅ PASO 5: Creación de splits con verificación\n",
    "train_period = 189\n",
    "test_period = 63\n",
    "\n",
    "if len(ticker_X) < train_period + test_period:\n",
    "    raise ValueError(f\"Datos insuficientes: se necesitan {train_period + test_period} filas, \"\n",
    "                    f\"pero solo hay {len(ticker_X)} disponibles\")\n",
    "\n",
    "train_X_split_1 = ticker_X.iloc[0:train_period]\n",
    "train_y_split_1 = ticker_y.iloc[0:train_period]\n",
    "test_X_split_1 = ticker_X.iloc[train_period:train_period + test_period]\n",
    "\n",
    "print(f\"✅ Splits creados correctamente:\")\n",
    "print(f\"   - train_X_split_1: {train_X_split_1.shape}\")\n",
    "print(f\"   - train_y_split_1: {train_y_split_1.shape}\")\n",
    "print(f\"   - test_X_split_1: {test_X_split_1.shape}\")\n",
    "\n",
    "# --- 2. FUNCIÓN DE ENTRENAMIENTO ROBUSTA ---\n",
    "def train_and_predict_on_split(train_X, train_y, test_X):\n",
    "    \"\"\"\n",
    "    Función que replica la arquitectura auditada para un solo split.\n",
    "    Con verificaciones adicionales de robustez.\n",
    "    \"\"\"\n",
    "    # ✅ Verificación inicial de alineación\n",
    "    assert len(train_X) == len(train_y), f\"Train desalineado: X={len(train_X)}, y={len(train_y)}\"\n",
    "    assert (train_X.index == train_y.index).all(), \"Índices de train no coinciden\"\n",
    "    \n",
    "    print(f\"   📊 Input data: train_X={train_X.shape}, train_y={train_y.shape}, test_X={test_X.shape}\")\n",
    "    \n",
    "    # a. Filtrado de datos (solo para entrenamiento)\n",
    "    valid_mask = train_y != 0\n",
    "    valid_index = train_y[valid_mask].index\n",
    "    train_X_filtered = train_X.loc[valid_index]\n",
    "    train_y_binary = train_y.loc[valid_index].map({-1: 0, 1: 1})\n",
    "    \n",
    "    if len(train_X_filtered) < 50:\n",
    "        print(f\"   ⚠️ Datos insuficientes tras filtrar: {len(train_X_filtered)} < 50\")\n",
    "        return None, None\n",
    "    \n",
    "    print(f\"   ✅ Datos filtrados: {train_X_filtered.shape[0]} filas válidas de {len(train_X)} originales\")\n",
    "    print(f\"   📊 Distribución de clases: {train_y_binary.value_counts().to_dict()}\")\n",
    "    \n",
    "    # b. Construcción del Pipeline\n",
    "    numeric_features = train_X_filtered.columns.tolist()\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', StandardScaler(), numeric_features)],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    primary_model_wf = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components=0.95)),\n",
    "        ('classifier', LGBMClassifier(\n",
    "            class_weight='balanced', \n",
    "            objective='binary', \n",
    "            random_state=42, \n",
    "            verbosity=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    print(f\"   ✅ Pipeline construido con {len(numeric_features)} características\")\n",
    "    \n",
    "    # c. Entrenamiento del modelo primario\n",
    "    try:\n",
    "        primary_model_wf.fit(train_X_filtered, train_y_binary)\n",
    "        print(f\"   ✅ Modelo primario entrenado exitosamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error en entrenamiento: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # d. Meta-Modelo y Predicción\n",
    "    primary_train_proba = primary_model_wf.predict_proba(train_X_filtered)\n",
    "    X_meta_train = pd.DataFrame({'p': primary_train_proba.max(axis=1)})\n",
    "    meta_model = LogisticRegression().fit(X_meta_train, train_y_binary)\n",
    "    \n",
    "    primary_train_preds = np.argmax(primary_train_proba, axis=1)\n",
    "    meta_train_probs = meta_model.predict_proba(X_meta_train)[:, 1]\n",
    "    \n",
    "    # Optimización de threshold\n",
    "    thresholds = np.arange(0.50, 0.70, 0.02)\n",
    "    best_f1 = -1\n",
    "    optimal_threshold = 0.55\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        mask = meta_train_probs >= thresh\n",
    "        if mask.sum() > 5:\n",
    "            f1 = f1_score(train_y_binary.iloc[mask], primary_train_preds[mask], zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, optimal_threshold = f1, thresh\n",
    "    \n",
    "    print(f\"   📈 Threshold óptimo: {optimal_threshold:.3f} (F1={best_f1:.3f})\")\n",
    "    \n",
    "    # Predicción en test\n",
    "    primary_test_proba = primary_model_wf.predict_proba(test_X)\n",
    "    primary_test_preds = np.argmax(primary_test_proba, axis=1)\n",
    "    meta_test_probs = meta_model.predict_proba(\n",
    "        pd.DataFrame({'p': primary_test_proba.max(axis=1)})\n",
    "    )[:, 1]\n",
    "    \n",
    "    entries = (meta_test_probs >= optimal_threshold)\n",
    "    buy_signals = pd.Series((primary_test_preds == 1) & entries, index=test_X.index)\n",
    "    sell_signals = pd.Series((primary_test_preds == 0) & entries, index=test_X.index)\n",
    "    \n",
    "    print(f\"   🎯 Señales generadas: {buy_signals.sum()} compras, {sell_signals.sum()} ventas\")\n",
    "    \n",
    "    return buy_signals, sell_signals\n",
    "\n",
    "# --- 3. PRUEBA DE FUEGO ---\n",
    "print(f\"\\n🔥 EJECUTANDO PRUEBA DE FUEGO...\")\n",
    "try:\n",
    "    buy_s, sell_s = train_and_predict_on_split(train_X_split_1, train_y_split_1, test_X_split_1)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"🎉 RESULTADO: PRUEBA SUPERADA\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if buy_s is not None:\n",
    "        print(f\"✅ La función se ejecutó sin errores\")\n",
    "        print(f\"📊 Señales generadas en el primer split:\")\n",
    "        print(f\"   - Compras: {buy_s.sum()}\")\n",
    "        print(f\"   - Ventas: {sell_s.sum()}\")\n",
    "        print(f\"   - Total entradas: {(buy_s | sell_s).sum()}\")\n",
    "        print(f\"   - Cobertura: {(buy_s | sell_s).sum() / len(buy_s) * 100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"✅ La función se ejecutó correctamente\")\n",
    "        print(f\"⚠️ No se generaron señales (datos insuficientes tras filtrar)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"❌ RESULTADO: PRUEBA FALLIDA\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Error encontrado: {str(e)}\")\n",
    "    print(f\"\\n📋 Traceback completo:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n🏁 Prueba de fuego completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b02ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Ejecutando el Walk-Forward Analysis completo ---\n",
      "\n",
      "========================= PROCESANDO TICKER: ADA-USD =========================\n",
      " -> Ejecutando 4 splits para ADA-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 204 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 111, 0: 93}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 15 compras, 48 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 267 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 143, 0: 124}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 43 compras, 20 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 319 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 162, 0: 157}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 45 compras, 18 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 381 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 191, 0: 190}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 48 compras, 15 ventas\n",
      " ✔️ RESULTADOS PARA ADA-USD: Total Return: -18.71%, Win Rate: 45.24%, Trades: 42\n",
      "\n",
      "========================= PROCESANDO TICKER: BNB-USD =========================\n",
      " -> Ejecutando 4 splits para BNB-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 205 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 113, 0: 92}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=0.996)\n",
      "   🎯 Señales generadas: 56 compras, 7 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 266 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 153, 0: 113}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 54 compras, 9 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 328 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 183, 0: 145}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 14 compras, 49 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 387 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 206, 0: 181}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 15 compras, 48 ventas\n",
      " ✔️ RESULTADOS PARA BNB-USD: Total Return: 6.78%, Win Rate: 58.82%, Trades: 34\n",
      "\n",
      "========================= PROCESANDO TICKER: BTC-USD =========================\n",
      " -> Ejecutando 4 splits para BTC-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 200 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {0: 102, 1: 98}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 254 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 134, 0: 120}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 57 compras, 6 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 311 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 165, 0: 146}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 37 compras, 26 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 370 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 191, 0: 179}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 40 compras, 23 ventas\n",
      " ✔️ RESULTADOS PARA BTC-USD: Total Return: 17.05%, Win Rate: 58.62%, Trades: 30\n",
      "\n",
      "========================= PROCESANDO TICKER: DOGE-USD =========================\n",
      " -> Ejecutando 4 splits para DOGE-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 204 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {0: 114, 1: 90}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 267 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {0: 146, 1: 121}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 330 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {0: 183, 1: 147}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 389 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {0: 220, 1: 169}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      " -> No se generaron operaciones para DOGE-USD en todo el análisis.\n",
      "\n",
      "========================= PROCESANDO TICKER: DOT-USD =========================\n",
      " -> Ejecutando 4 splits para DOT-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 207 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 110, 0: 97}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 40 compras, 23 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 270 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 150, 0: 120}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 22 compras, 41 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 332 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 178, 0: 154}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 55 compras, 8 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 394 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 214, 0: 180}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 48 compras, 15 ventas\n",
      " ✔️ RESULTADOS PARA DOT-USD: Total Return: -33.10%, Win Rate: 52.63%, Trades: 57\n",
      "\n",
      "========================= PROCESANDO TICKER: ETH-USD =========================\n",
      " -> Ejecutando 4 splits para ETH-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 206 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 120, 0: 86}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=0.996)\n",
      "   🎯 Señales generadas: 26 compras, 37 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 266 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 157, 0: 109}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 16 compras, 47 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 327 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 195, 0: 132}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 49 compras, 14 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 387 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 220, 0: 167}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 34 compras, 29 ventas\n",
      " ✔️ RESULTADOS PARA ETH-USD: Total Return: -16.17%, Win Rate: 56.86%, Trades: 51\n",
      "\n",
      "========================= PROCESANDO TICKER: LINK-USD =========================\n",
      " -> Ejecutando 4 splits para LINK-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 207 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 118, 0: 89}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 28 compras, 35 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 270 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 154, 0: 116}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 38 compras, 25 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 332 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 182, 0: 150}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 18 compras, 45 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 395 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 217, 0: 178}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 23 compras, 40 ventas\n",
      " ✔️ RESULTADOS PARA LINK-USD: Total Return: 25.88%, Win Rate: 46.15%, Trades: 52\n",
      "\n",
      "========================= PROCESANDO TICKER: LTC-USD =========================\n",
      " -> Ejecutando 4 splits para LTC-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 207 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 111, 0: 96}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 38 compras, 25 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 269 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 148, 0: 121}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 12 compras, 51 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 332 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 188, 0: 144}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 58 compras, 5 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 393 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 217, 0: 176}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 50 compras, 13 ventas\n",
      " ✔️ RESULTADOS PARA LTC-USD: Total Return: -30.22%, Win Rate: 47.92%, Trades: 49\n",
      "\n",
      "========================= PROCESANDO TICKER: MATIC-USD =========================\n",
      " -> Ejecutando 4 splits para MATIC-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 205 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 109, 0: 96}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 41 compras, 22 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 268 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 138, 0: 130}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 1 compras, 62 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 331 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 176, 0: 155}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 25 compras, 38 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 394 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 203, 0: 191}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 26 compras, 37 ventas\n",
      " ✔️ RESULTADOS PARA MATIC-USD: Total Return: 52.70%, Win Rate: 52.17%, Trades: 46\n",
      "\n",
      "========================= PROCESANDO TICKER: SHIB-USD =========================\n",
      " -> Ejecutando 2 splits para SHIB-USD...\n",
      "   📊 Input data: train_X=(216, 19), train_y=(216,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 210 filas válidas de 216 originales\n",
      "   📊 Distribución de clases: {1: 117, 0: 93}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 36 compras, 27 ventas\n",
      "   📊 Input data: train_X=(279, 19), train_y=(279,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 268 filas válidas de 279 originales\n",
      "   📊 Distribución de clases: {1: 140, 0: 128}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 18 compras, 45 ventas\n",
      " ✔️ RESULTADOS PARA SHIB-USD: Total Return: -32.60%, Win Rate: 26.32%, Trades: 19\n",
      "\n",
      "========================= PROCESANDO TICKER: SOL-USD =========================\n",
      " -> Ejecutando 4 splits para SOL-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 207 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {1: 127, 0: 80}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=0.996)\n",
      "   🎯 Señales generadas: 27 compras, 36 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 270 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 172, 0: 98}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 28 compras, 35 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 333 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {1: 205, 0: 128}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 54 compras, 9 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 396 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {1: 229, 0: 167}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 26 compras, 37 ventas\n",
      " ✔️ RESULTADOS PARA SOL-USD: Total Return: -38.63%, Win Rate: 48.28%, Trades: 58\n",
      "\n",
      "========================= PROCESANDO TICKER: XRP-USD =========================\n",
      " -> Ejecutando 4 splits para XRP-USD...\n",
      "   📊 Input data: train_X=(207, 19), train_y=(207,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 207 filas válidas de 207 originales\n",
      "   📊 Distribución de clases: {0: 104, 1: 103}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "   📊 Input data: train_X=(270, 19), train_y=(270,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 268 filas válidas de 270 originales\n",
      "   📊 Distribución de clases: {1: 137, 0: 131}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.500 (F1=1.000)\n",
      "   🎯 Señales generadas: 37 compras, 26 ventas\n",
      "   📊 Input data: train_X=(333, 19), train_y=(333,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 324 filas válidas de 333 originales\n",
      "   📊 Distribución de clases: {0: 163, 1: 161}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      "   📊 Input data: train_X=(396, 19), train_y=(396,), test_X=(63, 19)\n",
      "   ✅ Datos filtrados: 383 filas válidas de 396 originales\n",
      "   📊 Distribución de clases: {0: 196, 1: 187}\n",
      "   ✅ Pipeline construido con 19 características\n",
      "   ✅ Modelo primario entrenado exitosamente\n",
      "   📈 Threshold óptimo: 0.550 (F1=-1.000)\n",
      "   🎯 Señales generadas: 0 compras, 0 ventas\n",
      " ✔️ RESULTADOS PARA XRP-USD: Total Return: -20.45%, Win Rate: 33.33%, Trades: 12\n",
      "\n",
      "========================= INFORME AGREGADO FINAL DEL WALK-FORWARD =========================\n",
      "Rendimiento 'Out-of-Sample' de la estrategia por activo:\n",
      "           Total Return [%]  Max Drawdown [%]  Win Rate [%]  Total Trades  \\\n",
      "ADA-USD          -18.709520         49.963193     45.238095            42   \n",
      "BNB-USD            6.780725         39.079846     58.823529            34   \n",
      "BTC-USD           17.053422         19.693756     58.620690            30   \n",
      "DOT-USD          -33.095945         56.747091     52.631579            57   \n",
      "ETH-USD          -16.167385         42.607315     56.862745            51   \n",
      "LINK-USD          25.881158         29.503211     46.153846            52   \n",
      "LTC-USD          -30.219424         45.898152     47.916667            49   \n",
      "MATIC-USD         52.697963         37.955118     52.173913            46   \n",
      "SHIB-USD         -32.601060         38.403216     26.315789            19   \n",
      "SOL-USD          -38.631295         64.505800     48.275862            58   \n",
      "XRP-USD          -20.448735         27.546266     33.333333            12   \n",
      "\n",
      "           Sharpe Ratio  Sortino Ratio  \n",
      "ADA-USD       -0.248719      -0.367815  \n",
      "BNB-USD        0.452705       0.644757  \n",
      "BTC-USD        0.741669       1.195115  \n",
      "DOT-USD       -0.439103      -0.612449  \n",
      "ETH-USD       -0.200224      -0.280786  \n",
      "LINK-USD       0.852622       1.352425  \n",
      "LTC-USD       -0.528866      -0.699165  \n",
      "MATIC-USD      1.187987       2.074468  \n",
      "SHIB-USD      -1.689824      -2.237545  \n",
      "SOL-USD       -0.536474      -0.771385  \n",
      "XRP-USD       -1.241053      -1.562357  \n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# PASO 17: MÓDULO DE WALK-FORWARD ANALYSIS FINAL (BASADO EN CELDA 2)\n",
    "# ====================================================================\n",
    "import vectorbt as vbt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- [INICIO] Ejecutando el Walk-Forward Analysis completo ---\")\n",
    "\n",
    "# --- 1. PREPARACIÓN ---\n",
    "# Usamos las variables auditadas de la CELDA 1 y la función de la CELDA 2\n",
    "all_tickers = X_final_auditado['ticker'].unique()\n",
    "all_stats = []\n",
    "\n",
    "# --- 2. BUCLE PRINCIPAL POR CADA TICKER ---\n",
    "for ticker in all_tickers:\n",
    "    print(f\"\\n{'='*25} PROCESANDO TICKER: {ticker} {'='*25}\")\n",
    "    \n",
    "    # --- PREPARACIÓN DE DATOS (LÓGICA EXACTA DE TU CELDA 2) ---\n",
    "    ticker_mask = X_final_auditado['ticker'] == ticker\n",
    "    ticker_X = X_final_auditado[ticker_mask].drop(columns=['ticker'])\n",
    "    ticker_y = y_final_auditado[ticker_mask]\n",
    "\n",
    "    # Verificación\n",
    "    assert len(ticker_X) == len(ticker_y), \"Error de alineación inicial\"\n",
    "    assert (ticker_X.index == ticker_y.index).all(), \"Error de índice inicial\"\n",
    "    # --- FIN DE LA LÓGICA COPIADA ---\n",
    "\n",
    "    train_period = 189\n",
    "    test_period = 63\n",
    "    \n",
    "    if len(ticker_X) < train_period + test_period:\n",
    "        print(f\" -> Datos insuficientes. Saltando...\")\n",
    "        continue\n",
    "    \n",
    "    n_splits = (len(ticker_X) - train_period) // test_period\n",
    "    if n_splits < 1:\n",
    "        print(f\" -> No hay suficientes datos para un split. Saltando...\")\n",
    "        continue\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits, test_size=test_period)\n",
    "    \n",
    "    all_buy_signals = pd.Series(dtype=bool)\n",
    "    all_sell_signals = pd.Series(dtype=bool)\n",
    "    \n",
    "    print(f\" -> Ejecutando {n_splits} splits para {ticker}...\")\n",
    "    \n",
    "    # --- Bucle Interno por cada Split ---\n",
    "    for train_index, test_index in tscv.split(ticker_X):\n",
    "        split_train_X, split_test_X = ticker_X.iloc[train_index], ticker_X.iloc[test_index]\n",
    "        split_train_y, _ = ticker_y.iloc[train_index], ticker_y.iloc[test_index]\n",
    "        \n",
    "        # Ejecutamos nuestra función ya validada 'train_and_predict_on_split'\n",
    "        buy_s, sell_s = train_and_predict_on_split(split_train_X, split_train_y, split_test_X)\n",
    "        \n",
    "        if buy_s is not None:\n",
    "            all_buy_signals = pd.concat([all_buy_signals, buy_s])\n",
    "            all_sell_signals = pd.concat([all_sell_signals, sell_s])\n",
    "\n",
    "    # --- 3. BACKTEST PARA EL TICKER ACTUAL ---\n",
    "    if all_buy_signals.empty or all_buy_signals.sum() == 0:\n",
    "        print(f\" -> No se generaron operaciones para {ticker} en todo el análisis.\")\n",
    "        continue\n",
    "\n",
    "    all_buy_signals = all_buy_signals[~all_buy_signals.index.duplicated(keep='first')]\n",
    "    all_sell_signals = all_sell_signals.loc[all_buy_signals.index]\n",
    "    \n",
    "    # El precio 'close' está dentro de ticker_X\n",
    "    price_data_for_pf = ticker_X\n",
    "    \n",
    "    valid_indices = all_buy_signals.index.intersection(price_data_for_pf.index)\n",
    "    if valid_indices.empty: continue\n",
    "\n",
    "    wf_portfolio = vbt.Portfolio.from_signals(\n",
    "        close=price_data_for_pf.loc[valid_indices, 'close'],\n",
    "        entries=all_buy_signals.reindex(valid_indices, fill_value=False),\n",
    "        exits=all_sell_signals.reindex(valid_indices, fill_value=False),\n",
    "        fees=0.002, sl_stop=0.05, tp_stop=0.05, init_cash=100000, freq='D'\n",
    "    )\n",
    "    \n",
    "    ticker_stats = wf_portfolio.stats()\n",
    "    ticker_stats.name = ticker\n",
    "    all_stats.append(ticker_stats)\n",
    "    print(f\" ✔️ RESULTADOS PARA {ticker}: Total Return: {ticker_stats['Total Return [%]']:.2f}%, Win Rate: {ticker_stats['Win Rate [%]']:.2f}%, Trades: {ticker_stats['Total Trades']}\")\n",
    "\n",
    "# --- 4. INFORME FINAL AGREGADO ---\n",
    "print(f\"\\n{'='*25} INFORME AGREGADO FINAL DEL WALK-FORWARD {'='*25}\")\n",
    "if not all_stats:\n",
    "    print(\"No se generaron estadísticas para ningún ticker.\")\n",
    "else:\n",
    "    final_stats_df = pd.DataFrame(all_stats)\n",
    "    print(\"Rendimiento 'Out-of-Sample' de la estrategia por activo:\")\n",
    "    print(final_stats_df[['Total Return [%]', 'Max Drawdown [%]', 'Win Rate [%]', 'Total Trades', 'Sharpe Ratio', 'Sortino Ratio']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd79223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- [INICIO] Análisis de Sensibilidad del Riesgo ---\n",
      " -> Artefactos cargados correctamente.\n",
      " -> Generando señales de trading para todo el histórico...\n",
      "✅ Señales regeneradas correctamente.\n",
      "Signals shape: (459, 12)\n",
      "Entries shape: (459, 12)\n",
      "Exits shape: (459, 12)\n",
      " -> Preparando datos de precios...\n",
      "Close prices shape: (459, 12)\n",
      "Período de datos: 2021-01-03 00:00:00+00:00 a 2022-04-06 00:00:00+00:00\n",
      "Datos alineados: 459 fechas en común\n",
      "Total señales de entrada: 58\n",
      "Total señales de salida: 3\n",
      " -> Ejecutando backtests para múltiples niveles de riesgo...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef148b9382e94800b2765a747d8c5fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Simulando Niveles de Riesgo:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error con riesgo 0.010: 'Total Return [%]'\n",
      "Error con riesgo 0.015: 'Total Return [%]'\n",
      "Error con riesgo 0.020: 'Total Return [%]'\n",
      "Error con riesgo 0.025: 'Total Return [%]'\n",
      "Error con riesgo 0.030: 'Total Return [%]'\n",
      "Error con riesgo 0.035: 'Total Return [%]'\n",
      "Error con riesgo 0.040: 'Total Return [%]'\n",
      "Error con riesgo 0.045: 'Total Return [%]'\n",
      "Error con riesgo 0.050: 'Total Return [%]'\n",
      "Error con riesgo 0.055: 'Total Return [%]'\n",
      "Error con riesgo 0.060: 'Total Return [%]'\n",
      "Error con riesgo 0.065: 'Total Return [%]'\n",
      "Error con riesgo 0.070: 'Total Return [%]'\n",
      "Error con riesgo 0.075: 'Total Return [%]'\n",
      "Error con riesgo 0.080: 'Total Return [%]'\n",
      "Error con riesgo 0.085: 'Total Return [%]'\n",
      "Error con riesgo 0.090: 'Total Return [%]'\n",
      "Error con riesgo 0.095: 'Total Return [%]'\n",
      "Error con riesgo 0.100: 'Total Return [%]'\n",
      "✅ Simulaciones completadas.\n",
      "✅ Completadas 0 de 19 simulaciones.\n",
      "❌ ERROR: No se pudieron completar las simulaciones\n",
      "Revisando problema específico...\n",
      "Diagnosticando ticker: ADA-USD\n",
      "  Entradas: 7\n",
      "  Salidas: 0\n",
      "  Precios: 459 días\n",
      "\n",
      "--- [FIN] Análisis de Sensibilidad del Riesgo ---\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# CELDA 4: ANÁLISIS DE SENSIBILIDAD DEL RIESGO (VERSIÓN DEFINITIVA)\n",
    "# ====================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import vectorbt as vbt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"--- [INICIO] Análisis de Sensibilidad del Riesgo ---\")\n",
    "\n",
    "# --- 1. Cargar Artefactos ---\n",
    "if 'X_final_auditado' not in locals() or 'strategy_package' not in locals():\n",
    "    raise NameError(\"Por favor, ejecuta la CELDA 1 de este notebook primero.\")\n",
    "\n",
    "print(\" -> Artefactos cargados correctamente.\")\n",
    "primary_model = strategy_package['primary_model_pipeline']\n",
    "meta_model = strategy_package['meta_model']\n",
    "optimal_threshold = strategy_package['optimal_threshold']\n",
    "\n",
    "# --- 2. Generar Señales para Todo el Histórico ---\n",
    "print(\" -> Generando señales de trading para todo el histórico...\")\n",
    "all_tickers = X_final_auditado['ticker'].unique()\n",
    "all_signals_list = []\n",
    "\n",
    "for ticker in all_tickers:\n",
    "    ticker_data = X_final_auditado[X_final_auditado['ticker'] == ticker].drop(columns=['ticker'])\n",
    "    if ticker_data.empty: \n",
    "        continue\n",
    "        \n",
    "    primary_proba = primary_model.predict_proba(ticker_data)\n",
    "    primary_preds = np.argmax(primary_proba, axis=1)\n",
    "    meta_features = pd.DataFrame({'primary_model_prob': primary_proba.max(axis=1)}, index=ticker_data.index)\n",
    "    meta_confidence = meta_model.predict_proba(meta_features)[:, 1]\n",
    "    \n",
    "    passes_threshold = meta_confidence >= optimal_threshold\n",
    "    signals = np.zeros(len(ticker_data))\n",
    "    signals[(primary_preds == 1) & passes_threshold] = 1\n",
    "    signals[(primary_preds == 0) & passes_threshold] = -1\n",
    "    all_signals_list.append(pd.Series(signals, index=ticker_data.index, name=ticker))\n",
    "\n",
    "# REGENERAR las variables correctas (no usar las de prueba)\n",
    "signals_df = pd.concat(all_signals_list, axis=1)\n",
    "entries_real = signals_df == 1  # ✅ Usar datos reales\n",
    "exits_real = signals_df == -1   # ✅ Usar datos reales\n",
    "\n",
    "print(\"✅ Señales regeneradas correctamente.\")\n",
    "print(f\"Signals shape: {signals_df.shape}\")\n",
    "print(f\"Entries shape: {entries_real.shape}\")\n",
    "print(f\"Exits shape: {exits_real.shape}\")\n",
    "\n",
    "# --- 3. Preparar Datos de Precios Reales ---\n",
    "print(\" -> Preparando datos de precios...\")\n",
    "close_prices_real = X_final_auditado.pivot(columns='ticker', values='close')  # ✅ Usar datos reales\n",
    "\n",
    "print(f\"Close prices shape: {close_prices_real.shape}\")\n",
    "print(f\"Período de datos: {close_prices_real.index.min()} a {close_prices_real.index.max()}\")\n",
    "\n",
    "# Alinear todos los datos\n",
    "common_index = close_prices_real.index.intersection(entries_real.index)\n",
    "close_prices_real = close_prices_real.loc[common_index]\n",
    "entries_real = entries_real.loc[common_index]\n",
    "exits_real = exits_real.loc[common_index]\n",
    "\n",
    "print(f\"Datos alineados: {len(common_index)} fechas en común\")\n",
    "print(f\"Total señales de entrada: {entries_real.sum().sum()}\")\n",
    "print(f\"Total señales de salida: {exits_real.sum().sum()}\")\n",
    "\n",
    "# --- 4. Verificar que hay señales válidas ---\n",
    "if entries_real.sum().sum() == 0:\n",
    "    print(\"❌ ERROR: No hay señales de entrada válidas\")\n",
    "    raise ValueError(\"No se pueden ejecutar backtests sin señales de entrada\")\n",
    "\n",
    "if exits_real.sum().sum() == 0:\n",
    "    print(\"❌ ERROR: No hay señales de salida válidas\")\n",
    "    raise ValueError(\"No se pueden ejecutar backtests sin señales de salida\")\n",
    "\n",
    "# --- 5. Ejecutar Backtest Parametrizado ---\n",
    "print(\" -> Ejecutando backtests para múltiples niveles de riesgo...\")\n",
    "\n",
    "risk_levels = np.arange(0.01, 0.105, 0.005)\n",
    "results_list = []\n",
    "\n",
    "for risk in tqdm(risk_levels, desc=\"Simulando Niveles de Riesgo\"):\n",
    "    try:\n",
    "        portfolio = vbt.Portfolio.from_signals(\n",
    "            close=close_prices_real,\n",
    "            entries=entries_real,\n",
    "            exits=exits_real,\n",
    "            size=risk * 100,  # Convertir a porcentaje\n",
    "            size_type='Percent',\n",
    "            fees=0.002,\n",
    "            sl_stop=0.05,\n",
    "            init_cash=100000,\n",
    "            freq='D'\n",
    "        )\n",
    "        \n",
    "        # Obtener estadísticas con nombres correctos\n",
    "        stats = portfolio.stats(['Total Return [%]', 'Max Drawdown [%]'])\n",
    "        \n",
    "        results_list.append({\n",
    "            'risk_per_trade': risk,\n",
    "            'Total Return': stats['Total Return [%]'],\n",
    "            'Max Drawdown': stats['Max Drawdown [%]']\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error con riesgo {risk:.3f}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convertir resultados a DataFrame\n",
    "results = pd.DataFrame(results_list)\n",
    "\n",
    "print(\"✅ Simulaciones completadas.\")\n",
    "print(f\"✅ Completadas {len(results)} de {len(risk_levels)} simulaciones.\")\n",
    "\n",
    "if results.empty:\n",
    "    print(\"❌ ERROR: No se pudieron completar las simulaciones\")\n",
    "    print(\"Revisando problema específico...\")\n",
    "    \n",
    "    # Diagnóstico específico del primer ticker\n",
    "    first_ticker = close_prices_real.columns[0]\n",
    "    print(f\"Diagnosticando ticker: {first_ticker}\")\n",
    "    print(f\"  Entradas: {entries_real[first_ticker].sum()}\")\n",
    "    print(f\"  Salidas: {exits_real[first_ticker].sum()}\")\n",
    "    print(f\"  Precios: {close_prices_real[first_ticker].dropna().shape[0]} días\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n--- Resultados del Análisis de Sensibilidad ---\")\n",
    "    print(results)\n",
    "\n",
    "    # --- 6. Análisis de Resultados ---\n",
    "    # Encontrar configuración óptima\n",
    "    results['risk_adjusted_return'] = results['Total Return'] / (results['Max Drawdown'] + 0.01)  # +0.01 para evitar división por 0\n",
    "    best_config = results.loc[results['risk_adjusted_return'].idxmax()]\n",
    "    \n",
    "    print(f\"\\n--- Configuración Óptima ---\")\n",
    "    print(f\"Riesgo por operación: {best_config['risk_per_trade']:.3f} ({best_config['risk_per_trade']*100:.1f}%)\")\n",
    "    print(f\"Retorno total: {best_config['Total Return']:.2f}%\")\n",
    "    print(f\"Máximo drawdown: {best_config['Max Drawdown']:.2f}%\")\n",
    "    print(f\"Ratio riesgo-ajustado: {best_config['risk_adjusted_return']:.2f}\")\n",
    "\n",
    "    # --- 7. Visualización ---\n",
    "    print(\"\\n -> Generando gráficos...\")\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Gráfico 1: Scatter plot\n",
    "    results['risk_per_trade_pct'] = results['risk_per_trade'] * 100\n",
    "    scatter = ax1.scatter(results['Max Drawdown'], results['Total Return'], \n",
    "                         s=100, c=results['risk_per_trade_pct'], \n",
    "                         cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    # Marcar punto óptimo\n",
    "    ax1.scatter(best_config['Max Drawdown'], best_config['Total Return'], \n",
    "               s=200, c='red', marker='*', edgecolor='black', linewidth=2, \n",
    "               label=f'Óptimo ({best_config[\"risk_per_trade\"]*100:.1f}%)')\n",
    "    \n",
    "    ax1.set_title('Análisis de Sensibilidad: Drawdown vs. Retorno', fontsize=14)\n",
    "    ax1.set_xlabel('Máximo Drawdown (%)', fontsize=12)\n",
    "    ax1.set_ylabel('Retorno Total (%)', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, ax=ax1)\n",
    "    cbar.set_label('Riesgo por Operación (%)', fontsize=10)\n",
    "\n",
    "    # Gráfico 2: Líneas de tendencia\n",
    "    ax2.plot(results['risk_per_trade_pct'], results['Total Return'], \n",
    "             'o-', label='Retorno Total', linewidth=2, markersize=6)\n",
    "    ax2.plot(results['risk_per_trade_pct'], results['Max Drawdown'], \n",
    "             's-', label='Max Drawdown', linewidth=2, markersize=6)\n",
    "    \n",
    "    # Marcar punto óptimo\n",
    "    ax2.axvline(best_config['risk_per_trade']*100, color='red', linestyle='--', \n",
    "               alpha=0.7, label=f'Óptimo ({best_config[\"risk_per_trade\"]*100:.1f}%)')\n",
    "    \n",
    "    ax2.set_title('Métricas vs. Nivel de Riesgo', fontsize=14)\n",
    "    ax2.set_xlabel('Riesgo por Operación (%)', fontsize=12)\n",
    "    ax2.set_ylabel('Valor (%)', fontsize=12)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- 8. Recomendaciones Finales ---\n",
    "    print(\"\\n--- RECOMENDACIONES FINALES ---\")\n",
    "    \n",
    "    returns_std = results['Total Return'].std()\n",
    "    drawdown_std = results['Max Drawdown'].std()\n",
    "    \n",
    "    print(f\"Volatilidad de retornos: {returns_std:.2f}%\")\n",
    "    print(f\"Volatilidad de drawdowns: {drawdown_std:.2f}%\")\n",
    "    \n",
    "    # Recomendaciones por perfil de riesgo\n",
    "    low_dd_mask = results['Max Drawdown'] <= results['Max Drawdown'].quantile(0.3)\n",
    "    if low_dd_mask.any():\n",
    "        conservative_idx = results[low_dd_mask]['Total Return'].idxmax()\n",
    "        conservative_config = results.loc[conservative_idx]\n",
    "        print(f\"\\n📊 PERFIL CONSERVADOR:\")\n",
    "        print(f\"  Riesgo: {conservative_config['risk_per_trade']*100:.1f}%\")\n",
    "        print(f\"  Retorno: {conservative_config['Total Return']:.2f}%\")\n",
    "        print(f\"  Drawdown: {conservative_config['Max Drawdown']:.2f}%\")\n",
    "    \n",
    "    high_return_mask = results['Total Return'] >= results['Total Return'].quantile(0.7)\n",
    "    if high_return_mask.any():\n",
    "        aggressive_idx = results[high_return_mask]['Max Drawdown'].idxmin()\n",
    "        aggressive_config = results.loc[aggressive_idx]\n",
    "        print(f\"\\n🚀 PERFIL AGRESIVO:\")\n",
    "        print(f\"  Riesgo: {aggressive_config['risk_per_trade']*100:.1f}%\")\n",
    "        print(f\"  Retorno: {aggressive_config['Total Return']:.2f}%\")\n",
    "        print(f\"  Drawdown: {aggressive_config['Max Drawdown']:.2f}%\")\n",
    "\n",
    "print(\"\\n--- [FIN] Análisis de Sensibilidad del Riesgo ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptonita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
